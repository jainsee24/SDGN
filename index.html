<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>SDGN: Leveraging Depth Guidance and Spatial Reasoning for Single-View NeRF Reconstruction</title>
</head>
<body>

<h1>SDGN: Leveraging Depth Guidance and Spatial Reasoning for Single-View NeRF Reconstruction</h1>
<p><strong>Authors:</strong> Seemandhar Jain</p>
<p><strong>Affiliation:</strong> University of Illinois Urbana-Champaign</p>
<p><strong>Contact:</strong> <a href="mailto:sj68@illinois.edu">sj68@illinois.edu</a></p>

<h2>Abstract</h2>
<p>We propose SDGN, a novel approach to advance the field of 3D reconstruction of indoor scenes by incorporating depth information and spatial vision-language reasoning into an optimized Neural Radiance Fields (NeRF) framework. This approach makes significant strides in indoor scene understanding and modeling, enabling efficient and high-fidelity 3D reconstruction from a single image.</p>

<h2>Introduction</h2>
<p>The specific objectives of this project are:</p>
<ul>
<li>To adapt an optimized NeRF model for enhanced processing speed and resource efficiency.</li>
<li>To integrate depth cues from the NYUv2 and SUNRGBD datasets into the NeRF pipeline, enhancing the model's ability to reconstruct complex indoor scenes accurately.</li>
<li>To evaluate the performance improvements in terms of accuracy and efficiency against traditional NeRF implementations and other leading 3D reconstruction techniques.</li>
</ul>

<h2>Related Work</h2>
<p>The section reviews literature on single-view 3D Reconstruction, Neural Radiance Fields (NeRF), Depth-guided NeRF, and Language-guided 3D Understanding, discussing various contributions and limitations of existing methods.</p>

<h2>Our Approach- SDGN</h2>
<p>The SDGN model integrates depth information derived from the NYUv2 and SUNRGBD datasets using state-of-the-art methods like KYN into an optimized NeRF framework, aiming to improve the fidelity and efficiency of 3D reconstructions from a single image.</p>

<h2>Experiments</h2>
<h3>Datasets Used</h3>
<p>The project utilizes the NYU Depth Dataset V2 and the SUN RGB-D Dataset, providing a comprehensive foundation for training and evaluating the enhanced NeRF model.</p>

<h3>Evaluation Protocol</h3>
<p>We adhere to the experimental methods described for assessing 3D occupancy prediction and focus on both scene and object-level evaluations.</p>

<h2>Challenges and Anticipated Reservations</h2>
<p>Discusses computational complexity, generalization to unseen scenes, dependency on depth estimation, evaluation metrics, and scalability to large-scale scenes.</p>

<h2>Next Steps/Future Work</h2>
<p>Proposes future research directions such as incorporating additional modalities, unsupervised depth estimation, real-time reconstruction, domain adaptation, interactive refinement, and application-specific optimizations.</p>

<h2>Conclusion</h2>
<p>SDGN advances the field of single-view 3D reconstruction by incorporating depth guidance from monocular depth estimation methods, demonstrating significant improvements over existing methods.</p>

<h2>About the Author</h2>
<p>The author is pursuing an MSCS at UIUC, specializing in 3D reconstruction with an ongoing interest in advancing 3D reconstruction methods.</p>

</body>
</html>
